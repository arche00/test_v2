import streamlit as st
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import joblib
import os
import requests
import json
from typing import Optional, Dict, Any
import time

# config.json íŒŒì¼ì—ì„œ API í† í° ë¡œë“œ
def load_api_token():
    try:
        # ë¨¼ì € Streamlit secretsì—ì„œ í† í° í™•ì¸
        if 'huggingface_api_token' in st.secrets:
            return st.secrets['huggingface_api_token']
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ í† í° í™•ì¸
        token = os.environ.get('HUGGINGFACE_API_TOKEN')
        if token:
            return token
            
        # ë¡œì»¬ config.jsonì—ì„œ í† í° í™•ì¸ (ê°œë°œ í™˜ê²½ìš©)
        if os.path.exists('config.json'):
            with open('config.json', 'r') as f:
                config = json.load(f)
                return config.get('huggingface_api_token')
                
        return None
    except Exception as e:
        print(f"í† í° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# API í† í° ì´ˆê¸°í™”
if 'hf_api_token' not in st.session_state:
    api_token = load_api_token()
    if api_token:
        st.session_state.hf_api_token = api_token
        print(f"API í† í°ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("API í† í°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="íŒ¨í„´ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
    <style>
    .stText {
        writing-mode: horizontal-tb;
        font-size: 24px;
    }
    .prediction-text {
        font-size: 28px;
        font-weight: bold;
        color: #FF4B4B;
    }
    </style>
""", unsafe_allow_html=True)

def get_pattern_transitions():
    """
    DBì—ì„œ íŒ¨í„´ ì „ì´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ê°€ì¥ ìµœê·¼ 150ê°œì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        conn = sqlite3.connect('pattern_analysis_v2.db')
        c = conn.cursor()
        
        # ê°€ì¥ ìµœê·¼ 150ê°œì˜ íŒ¨í„´ ì „ì´ ë°ì´í„° ì¡°íšŒ
        transitions = c.execute('''
            SELECT 
                pattern1, result1, pattern2, result2,
                prev_pattern1, prev_pattern2, transition_type,
                transition_count,
                pattern1_banker_count, pattern1_player_count,
                pattern2_banker_count, pattern2_player_count,
                pattern1_transitions, pattern2_transitions,
                timestamp
            FROM pattern_records
            ORDER BY timestamp DESC
            LIMIT 150
        ''').fetchall()
        
        # ë°ì´í„°ë¥¼ ì›ë˜ ìˆœì„œ(ì˜¤ë˜ëœ ê²ƒ -> ìµœì‹  ê²ƒ)ë¡œ ë’¤ì§‘ê¸° (ì„ íƒì‚¬í•­, ì˜ˆì¸¡ ë¡œì§ì— ë”°ë¼ í•„ìš”í•  ìˆ˜ ìˆìŒ)
        # transitions.reverse()
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(transitions, columns=[
            'pattern1', 'result1', 'pattern2', 'result2',
            'prev_pattern1', 'prev_pattern2', 'transition_type',
            'transition_count',
            'pattern1_banker_count', 'pattern1_player_count',
            'pattern2_banker_count', 'pattern2_player_count',
            'pattern1_transitions', 'pattern2_transitions',
            'timestamp'
        ])
        
        # timestamp ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (ì˜ˆì¸¡ í•¨ìˆ˜ë“¤ì´ ì‹œê°„ ìˆœì„œë¥¼ ê°€ì •í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        df = df.sort_values(by='timestamp', ascending=True)
        
        if df.empty:
            st.warning("ë°ì´í„°ë² ì´ìŠ¤ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        elif len(df) < 150:
            st.warning(f"ë°ì´í„°ê°€ 150ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤ ({len(df)}ê°œ). ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ìµœì‹  ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            st.info(f"ê°€ì¥ ìµœì‹  ë°ì´í„° {len(df)}ê°œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
        conn.close()
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def predict_next_pattern(df: pd.DataFrame, current_pattern: str) -> Optional[Dict[str, Any]]:
    """
    í˜„ì¬ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ íŒ¨í„´ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    if df is None or df.empty or not current_pattern:
        return None
    
    # í˜„ì¬ íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì „ì´ íŒ¨í„´ ì°¾ê¸°
    pattern_data = df[
        (df['pattern1'] == current_pattern) | 
        (df['pattern2'] == current_pattern)
    ]
    
    if pattern_data.empty:
        return None
    
    # íŒ¨í„´1ì¸ ê²½ìš°
    pattern1_next = pattern_data[pattern_data['pattern1'] == current_pattern]['result1'].value_counts()
    # íŒ¨í„´2ì¸ ê²½ìš°
    pattern2_next = pattern_data[pattern_data['pattern2'] == current_pattern]['result2'].value_counts()
    
    # ë‘ ê²°ê³¼ í•©ì¹˜ê¸°
    next_patterns = pd.concat([pattern1_next, pattern2_next]).groupby(level=0).sum()
    
    if next_patterns.empty:
        return None
    
    total_occurrences = len(pattern_data)
    best_next = next_patterns.index[0]
    confidence = next_patterns.iloc[0] / total_occurrences
    
    # ì‹ ë¢°ë„ê°€ 50% ë¯¸ë§Œì´ë©´ ë°˜ëŒ€ íŒ¨í„´ì´ ë” ë†’ì€ í™•ë¥ 
    if confidence < 0.5:
        best_next = 'b' if best_next == 'a' else 'a'
        confidence = 1 - confidence
    
    # ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
    debug_info = {
        'pattern': current_pattern,
        'total_matches': total_occurrences,
        'pattern1_matches': len(pattern1_next),
        'pattern2_matches': len(pattern2_next),
        'next_patterns': next_patterns.to_dict(),
        'confidence_adjusted': confidence >= 0.5
    }
    
    return {
        'next_pattern': best_next,
        'confidence': confidence,
        'method': 'ë¹ˆë„ ê¸°ë°˜',
        'debug_info': debug_info
    }

def predict_next_pattern2(df, current_pattern1, current_pattern2):
    """
    í˜„ì¬ íŒ¨í„´1ê³¼ íŒ¨í„´2ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ íŒ¨í„´ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    if df is None or df.empty or not current_pattern1 or not current_pattern2:
        return None
    
    # í˜„ì¬ íŒ¨í„´1ê³¼ íŒ¨í„´2ë¡œ ì‹œì‘í•˜ëŠ” ì „ì´ íŒ¨í„´ ì°¾ê¸°
    transitions = df[(df['prev_pattern1'] == current_pattern1) & 
                    (df['prev_pattern2'] == current_pattern2)]
    if transitions.empty:
        return None
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ ë‹¤ìŒ íŒ¨í„´ ì°¾ê¸°
    next_patterns = transitions['pattern1'].value_counts()
    if next_patterns.empty:
        return None
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜
    return {
        'next_pattern': next_patterns.index[0],
        'confidence': next_patterns.iloc[0] / len(transitions),
        'total_occurrences': len(transitions)
    }

def prepare_training_data():
    """
    ML ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    """
    try:
        conn = sqlite3.connect('pattern_analysis_v2.db')
        
        # ì „ì²´ ë°ì´í„° ì¡°íšŒ
        query = '''
            SELECT 
                pattern1, result1, pattern2, result2,
                pattern1_banker_count, pattern1_player_count,
                pattern2_banker_count, pattern2_player_count,
                pattern1_transitions, pattern2_transitions,
                timestamp
            FROM pattern_records
            ORDER BY timestamp
        '''
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        # íŠ¹ì„±(X)ê³¼ ë ˆì´ë¸”(y) ì¤€ë¹„
        features = ['pattern1_banker_count', 'pattern1_player_count',
                   'pattern1_transitions', 'pattern2_banker_count',
                   'pattern2_player_count', 'pattern2_transitions']
        
        X = df[features].values
        y = df['result1'].values  # ë‹¤ìŒ ê²°ê³¼ ì˜ˆì¸¡
        
        return X, y, features
    except Exception as e:
        st.error(f"í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, None, None

def train_ml_model():
    """
    RandomForest ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
    """
    X, y, features = prepare_training_data()
    if X is None or y is None:
        return None
    
    # ë ˆì´ë¸” ì¸ì½”ë”©
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    
    # ëª¨ë¸ í•™ìŠµ
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y_encoded)
    
    # ëª¨ë¸ ì €ì¥
    model_path = 'pattern_prediction_model.joblib'
    joblib.dump((model, le, features), model_path)
    
    return model, le, features

def predict_with_ml(current_pattern1, current_pattern2=None):
    """
    ML ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ íŒ¨í„´ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    try:
        # ëª¨ë¸ ë¡œë“œ
        model_path = 'pattern_prediction_model.joblib'
        if not os.path.exists(model_path):
            model, le, features = train_ml_model()
        else:
            model, le, features = joblib.load(model_path)
        
        # í˜„ì¬ íŒ¨í„´ì˜ íŠ¹ì„± ì¶”ì¶œ
        conn = sqlite3.connect('pattern_analysis_v2.db')
        c = conn.cursor()
        
        query = '''
            SELECT 
                pattern1_banker_count, pattern1_player_count,
                pattern1_transitions, pattern2_banker_count,
                pattern2_player_count, pattern2_transitions
            FROM pattern_records
            WHERE pattern1 = ? AND pattern2 = ?
            ORDER BY timestamp DESC
            LIMIT 1
        '''
        
        row = c.execute(query, (current_pattern1, current_pattern2 or current_pattern1)).fetchone()
        conn.close()
        
        if row is None:
            return None
        
        # ì˜ˆì¸¡
        X_pred = np.array(row).reshape(1, -1)
        y_pred = model.predict_proba(X_pred)
        
        # ê²°ê³¼ ë³€í™˜
        predicted_class = le.inverse_transform([np.argmax(y_pred)])[0]
        confidence = np.max(y_pred)
        
        return {
            'next_pattern': predicted_class,
            'confidence': confidence,
            'method': 'ML Model (RandomForest)'
        }
        
    except Exception as e:
        st.error(f"ML ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def get_huggingface_prediction(pattern: str) -> Optional[Dict[str, Any]]:
    """
    Hugging Face APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒ¨í„´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    API_TOKEN = st.session_state.get("hf_api_token")
    if not API_TOKEN:
        return None

    # íŒ¨í„´ ë¶„ì„ìš© ëª¨ë¸ ì„ íƒ (text-classification ëª¨ë¸ ì‚¬ìš©)
    API_URL = "https://api-inference.huggingface.co/models/facebook/bart-large-mnli"
    headers = {"Authorization": f"Bearer {API_TOKEN}"}
    
    try:
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        payload = {
            "inputs": pattern,
            "parameters": {
                "candidate_labels": ["next_a", "next_b"]
            }
        }
        
        response = requests.post(API_URL, headers=headers, json=payload)
        
        if response.status_code == 200:
            result = response.json()
            
            # API ì‘ë‹µ ê²€ì¦
            if isinstance(result, dict) and 'scores' in result and 'labels' in result:
                # ìµœê³  í™•ë¥ ì˜ ì˜ˆì¸¡ê°’ ì„ íƒ
                max_score_idx = result['scores'].index(max(result['scores']))
                predicted_value = 'a' if result['labels'][max_score_idx] == 'next_a' else 'b'
                confidence = result['scores'][max_score_idx]
                
                # ì‹ ë¢°ë„ê°€ 50% ë¯¸ë§Œì´ë©´ ë°˜ëŒ€ íŒ¨í„´ ì„ íƒ
                if confidence < 0.5:
                    predicted_value = 'b' if predicted_value == 'a' else 'a'
                    confidence = 1 - confidence
                
                return {
                    'next_pattern': predicted_value,
                    'confidence': confidence,
                    'method': 'Hugging Face API',
                    'model_name': 'BART Large MNLI',
                    'raw_predictions': {
                        'next_a': result['scores'][result['labels'].index('next_a')],
                        'next_b': result['scores'][result['labels'].index('next_b')]
                    }
                }
            else:
                st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ API ì‘ë‹µ í˜•ì‹: {result}")
                return None
        else:
            st.error(f"API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def find_similar_patterns(df: pd.DataFrame, pattern: str) -> Optional[Dict[str, Any]]:
    """
    ìœ ì‚¬í•œ íŒ¨í„´ì„ ì°¾ì•„ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    if df is None or df.empty:
        return None
        
    # íŒ¨í„´ ê¸¸ì´ì™€ êµ¬ì„±ì´ ë¹„ìŠ·í•œ íŒ¨í„´ë“¤ì„ ì°¾ìŒ
    similar_patterns = df[
        (df['pattern1'].str.len() == len(pattern)) &
        (df['pattern1'].str.count('a') == pattern.count('a'))
    ]
    
    if similar_patterns.empty:
        return None
        
    # ê°€ì¥ ë¹ˆë²ˆí•œ ë‹¤ìŒ íŒ¨í„´ ì°¾ê¸°
    next_patterns = similar_patterns['result1'].value_counts()
    
    return {
        'next_pattern': next_patterns.index[0],
        'confidence': next_patterns.iloc[0] / len(similar_patterns),
        'method': 'ìœ ì‚¬ íŒ¨í„´ ê¸°ë°˜'
    }

def clear_database():
    """
    ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    try:
        conn = sqlite3.connect('pattern_analysis_v2.db')
        c = conn.cursor()
        
        # í…Œì´ë¸” ë°ì´í„° ì‚­ì œ
        c.execute('DELETE FROM pattern_records')
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        st.error(f"DB ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def update_database():
    """
    ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìµœì‹  ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    try:
        conn = sqlite3.connect('pattern_analysis_v2.db')
        c = conn.cursor()
        
        # ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ (ì˜ˆ: 30ì¼ ì´ìƒ)
        c.execute('''
            DELETE FROM pattern_records 
            WHERE timestamp < datetime('now', '-30 days')
        ''')
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        c.execute('''
            UPDATE pattern_records 
            SET transition_count = (
                SELECT COUNT(*) 
                FROM pattern_records pr2 
                WHERE pr2.pattern1 = pattern_records.pattern1
            )
        ''')
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        st.error(f"DB ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def analyze_pattern_combination(df: pd.DataFrame, pattern1: str, pattern2: str) -> Optional[Dict]:
    """
    ë‘ íŒ¨í„´ì˜ ì¡°í•©ì— ëŒ€í•œ í†µê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    if df is None or df.empty:
        return None
        
    # íŒ¨í„´ ì¡°í•© ì°¾ê¸°
    combined = df[
        ((df['pattern1'] == pattern1) & (df['pattern2'] == pattern2)) |
        ((df['prev_pattern1'] == pattern1) & (df['pattern1'] == pattern2))
    ]
    
    if combined.empty:
        return None
    
    # í†µê³„ ê³„ì‚°
    total_occurrences = len(combined)
    sequential = combined[
        ((df['pattern1'] == pattern1) & (df['pattern2'] == pattern2))
    ]
    sequential_prob = len(sequential) / total_occurrences if total_occurrences > 0 else 0
    
    avg_transitions = combined['transition_count'].mean() if 'transition_count' in combined.columns else 0
    
    return {
        'total_occurrences': total_occurrences,
        'sequential_probability': sequential_prob,
        'avg_transitions': avg_transitions
    }

def create_comparison_data(local_data, api_data):
    """ë¡œì»¬ê³¼ API ì˜ˆì¸¡ì„ ë¹„êµí•˜ì—¬ ì¼ì¹˜í•˜ëŠ” í•­ëª©ê³¼ ì°¨ì´ê°€ ìˆëŠ” í•­ëª©ì„ ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    matching_predictions = []
    differing_predictions = []
    
    if not api_data:
        return matching_predictions, differing_predictions
        
    local_dict = {item["íŒ¨í„´"]: item for item in local_data}
    api_dict = {item["íŒ¨í„´"]: item for item in api_data}
    
    for pattern in local_dict.keys():
        if pattern in api_dict:
            local_pred = local_dict[pattern]
            api_pred = api_dict[pattern]
            comparison_item = {
                "íŒ¨í„´": pattern,
                "ë¡œì»¬ ì˜ˆì¸¡": local_pred["ì˜ˆì¸¡ê°’"],
                "ë¡œì»¬ ì‹ ë¢°ë„": f"{local_pred['ì‹ ë¢°ë„']:.1%}",
                "API ì˜ˆì¸¡": api_pred["ì˜ˆì¸¡ê°’"],
                "API ì‹ ë¢°ë„": f"{api_pred['ì‹ ë¢°ë„']:.1%}"
            }
            if local_pred["ì˜ˆì¸¡ê°’"] == api_pred["ì˜ˆì¸¡ê°’"]:
                matching_predictions.append(comparison_item)
            else:
                differing_predictions.append(comparison_item)
                
    return matching_predictions, differing_predictions

def display_pattern_prediction_table(df):
    """
    íŒ¨í„´1(4ê°œ)ê³¼ íŒ¨í„´2(8ê°œ)ì˜ ì˜ˆì¸¡ê°’ì„ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ìˆ˜í‰ ë°°ì¹˜í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    st.markdown("## íŒ¨í„´ ì˜ˆì¸¡ ë¹„êµ í…Œì´ë¸”")
    
    # íŒ¨í„´1 (4ê°œ: aa, ab, ba, bb)
    pattern1_list = ['aa', 'ab', 'ba', 'bb']
    
    # íŒ¨í„´2 (8ê°œ: aaa, aab, aba, abb, baa, bab, bba, bbb)
    pattern2_list = ['aaa', 'aab', 'aba', 'abb', 'baa', 'bab', 'bba', 'bbb']
    
    def get_api_predictions(patterns):
        """API ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì ˆí•œ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        api_data = []
        api_error = None
        if "hf_api_token" in st.session_state:
            try:
                for pattern in patterns:
                    prediction = get_huggingface_prediction(pattern)
                    if prediction:
                        api_data.append({
                            "íŒ¨í„´": pattern,
                            "ì˜ˆì¸¡ê°’": prediction['next_pattern'],
                            "ì‹ ë¢°ë„": prediction['confidence']
                        })
            except Exception as e:
                api_error = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        return api_data, api_error
    
    def get_local_predictions(patterns, df):
        """ë¡œì»¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        local_data = []
        for pattern in patterns:
            prediction = predict_next_pattern(df, pattern)
            if prediction:
                local_data.append({
                    "íŒ¨í„´": pattern,
                    "ì˜ˆì¸¡ê°’": prediction['next_pattern'],
                    "ì‹ ë¢°ë„": prediction['confidence']
                })
        return local_data
    
    # íŒ¨í„´1ê³¼ íŒ¨í„´2 ì˜ˆì¸¡ì„ ìˆ˜í‰ìœ¼ë¡œ ë°°ì¹˜
    col1, col2 = st.columns([3, 3])
    
    # íŒ¨í„´1 ì˜ˆì¸¡
    with col1:
        st.markdown("### íŒ¨í„´1 ì˜ˆì¸¡ (aa, ab, ba, bb)")
        
        # ë¡œì»¬ê³¼ API ì˜ˆì¸¡ì„ ë‚˜ë€íˆ í‘œì‹œ
        subcol1, subcol2 = st.columns(2)
        
        # ë¡œì»¬ ì˜ˆì¸¡ (í•­ìƒ í‘œì‹œ)
        with subcol1:
            st.markdown("#### ë¡œì»¬ ê¸°ë°˜ ì˜ˆì¸¡")
            local_data1 = get_local_predictions(pattern1_list, df)
            if local_data1:
                st.table(pd.DataFrame([{
                    "íŒ¨í„´": d["íŒ¨í„´"],
                    "ì˜ˆì¸¡ê°’": d["ì˜ˆì¸¡ê°’"],
                    "ì‹ ë¢°ë„": f"{d['ì‹ ë¢°ë„']:.1%}"
                } for d in local_data1]))
            else:
                st.info("ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # API ì˜ˆì¸¡
        with subcol2:
            st.markdown("#### API ê¸°ë°˜ ì˜ˆì¸¡")
            api_data1, api_error1 = get_api_predictions(pattern1_list)
            if api_error1:
                st.error(api_error1)
            elif api_data1:
                st.table(pd.DataFrame([{
                    "íŒ¨í„´": d["íŒ¨í„´"],
                    "ì˜ˆì¸¡ê°’": d["ì˜ˆì¸¡ê°’"],
                    "ì‹ ë¢°ë„": f"{d['ì‹ ë¢°ë„']:.1%}"
                } for d in api_data1]))
            else:
                st.info("API í† í°ì„ ì„¤ì •í•˜ì„¸ìš”.")
        
        # ì˜ˆì¸¡ ë¹„êµ ë¶„ì„ (ì¼ì¹˜/ì°¨ì´ ë¶„ë¦¬)
        matching1, differing1 = create_comparison_data(local_data1, api_data1)
        
        if matching1:
            st.markdown("#### ì˜ˆì¸¡ ì¼ì¹˜ ë¶„ì„ (ë¡œì»¬ == API)")
            st.table(pd.DataFrame(matching1))
        
        if differing1:
            st.markdown("#### ì˜ˆì¸¡ ì°¨ì´ ë¶„ì„ (ë¡œì»¬ != API)")
            st.table(pd.DataFrame(differing1))
    
    # íŒ¨í„´2 ì˜ˆì¸¡
    with col2:
        st.markdown("### íŒ¨í„´2 ì˜ˆì¸¡ (aaa ~ bbb)")
        
        # ë¡œì»¬ê³¼ API ì˜ˆì¸¡ì„ ë‚˜ë€íˆ í‘œì‹œ
        subcol1, subcol2 = st.columns(2)
        
        # ë¡œì»¬ ì˜ˆì¸¡ (í•­ìƒ í‘œì‹œ)
        with subcol1:
            st.markdown("#### ë¡œì»¬ ê¸°ë°˜ ì˜ˆì¸¡")
            local_data2 = get_local_predictions(pattern2_list, df)
            if local_data2:
                st.table(pd.DataFrame([{
                    "íŒ¨í„´": d["íŒ¨í„´"],
                    "ì˜ˆì¸¡ê°’": d["ì˜ˆì¸¡ê°’"],
                    "ì‹ ë¢°ë„": f"{d['ì‹ ë¢°ë„']:.1%}"
                } for d in local_data2]))
            else:
                st.info("ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # API ì˜ˆì¸¡
        with subcol2:
            st.markdown("#### API ê¸°ë°˜ ì˜ˆì¸¡")
            api_data2, api_error2 = get_api_predictions(pattern2_list)
            if api_error2:
                st.error(api_error2)
            elif api_data2:
                st.table(pd.DataFrame([{
                    "íŒ¨í„´": d["íŒ¨í„´"],
                    "ì˜ˆì¸¡ê°’": d["ì˜ˆì¸¡ê°’"],
                    "ì‹ ë¢°ë„": f"{d['ì‹ ë¢°ë„']:.1%}"
                } for d in api_data2]))
            else:
                st.info("API í† í°ì„ ì„¤ì •í•˜ì„¸ìš”.")
        
        # ì˜ˆì¸¡ ë¹„êµ ë¶„ì„ (ì¼ì¹˜/ì°¨ì´ ë¶„ë¦¬)
        matching2, differing2 = create_comparison_data(local_data2, api_data2)
        
        if matching2:
            st.markdown("#### ì˜ˆì¸¡ ì¼ì¹˜ ë¶„ì„ (ë¡œì»¬ == API)")
            st.table(pd.DataFrame(matching2))
            
        if differing2:
            st.markdown("#### ì˜ˆì¸¡ ì°¨ì´ ë¶„ì„ (ë¡œì»¬ != API)")
            st.table(pd.DataFrame(differing2))

def main():
    st.title("íŒ¨í„´ ë¶„ì„ ì‹œìŠ¤í…œ")
    
    # ë°ì´í„° ë¡œë“œ
    df = get_pattern_transitions()
    if df is None:
        return
    
    # DB ê´€ë¦¬ ë²„íŠ¼ë“¤
    col1, col2 = st.columns(2)
    with col1:
        if st.button("DB ì—…ë°ì´íŠ¸"):
            if update_database():
                st.success("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.experimental_rerun()  # ì•±ì„ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë³€ê²½ì‚¬í•­ ë°˜ì˜
    with col2:
        if st.button("ML ëª¨ë¸ ì¬í•™ìŠµ"):
            with st.spinner("ëª¨ë¸ í•™ìŠµ ì¤‘..."):
                model, le, features = train_ml_model()
                if model is not None:
                    st.success("ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì˜ˆì¸¡ê°’ í…Œì´ë¸” í‘œì‹œ
    display_pattern_prediction_table(df)
    
    st.markdown("---")
    
    # ë¶„ì„ ì˜ì—­ êµ¬ë¶„
    left_col, right_col = st.columns(2)
    
    # ì™¼ìª½ ì»¬ëŸ¼: ë¡œì»¬ ë¶„ì„
    with left_col:
        st.markdown("## ë¡œì»¬ ê¸°ë°˜ íŒ¨í„´ ë¶„ì„")
        st.info("ğŸ“Š ë¹ ë¥¸ ì‘ë‹µì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•˜ì„¸ìš”. ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
        
        # íŒ¨í„´1 ì…ë ¥
        pattern1 = st.text_input("íŒ¨í„´1 ì…ë ¥ (ì˜ˆ: aa, ab, ba, bb)", key="pattern1_input_local")
        if pattern1:
            prediction1 = predict_next_pattern(df, pattern1)
            if prediction1:
                confidence_note = "ì§ì ‘ ì˜ˆì¸¡" if prediction1['debug_info']['confidence_adjusted'] else "ë°˜ëŒ€ íŒ¨í„´ ì˜ˆì¸¡"
                st.markdown(f"""
                    <div class="prediction-text">
                    <span style="color: #1f77b4;">íŒ¨í„´1 ì˜ˆì¸¡ ê²°ê³¼:</span><br>
                    ì˜ˆì¸¡ ë°©ë²•: {prediction1.get('method', 'ë¹ˆë„ ê¸°ë°˜')} ({confidence_note})<br>
                    ë‹¤ìŒ íŒ¨í„´ ì˜ˆì¸¡: {prediction1['next_pattern']}<br>
                    ì‹ ë¢°ë„: {prediction1['confidence']:.1%}<br>
                    </div>
                """, unsafe_allow_html=True)
                
                with st.expander("íŒ¨í„´1 ìƒì„¸ ì •ë³´"):
                    st.json(prediction1['debug_info'])
            else:
                st.warning("íŒ¨í„´1ì— ëŒ€í•œ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒ¨í„´2 ì…ë ¥
        pattern2 = st.text_input("íŒ¨í„´2 ì…ë ¥ (ì˜ˆ: aaa, aab, aba, abb)", key="pattern2_input_local")
        if pattern2:
            prediction2 = predict_next_pattern(df, pattern2)
            if prediction2:
                st.markdown(f"""
                    <div class="prediction-text">
                    <span style="color: #2ca02c;">íŒ¨í„´2 ì˜ˆì¸¡ ê²°ê³¼:</span><br>
                    ì˜ˆì¸¡ ë°©ë²•: {prediction2.get('method', 'ë¹ˆë„ ê¸°ë°˜')}<br>
                    ë‹¤ìŒ íŒ¨í„´ ì˜ˆì¸¡: {prediction2['next_pattern']}<br>
                    ì‹ ë¢°ë„: {prediction2['confidence']:.1%}<br>
                    </div>
                """, unsafe_allow_html=True)
                
                with st.expander("íŒ¨í„´2 ìƒì„¸ ì •ë³´"):
                    st.json(prediction2['debug_info'])
            else:
                st.warning("íŒ¨í„´2ì— ëŒ€í•œ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒ¨í„´ ì¡°í•© ë¶„ì„
        if pattern1 and pattern2:
            st.markdown("### íŒ¨í„´ ì¡°í•© ë¶„ì„")
            combined_stats = analyze_pattern_combination(df, pattern1, pattern2)
            if combined_stats:
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì „ì²´ ë°œìƒ íšŸìˆ˜", combined_stats['total_occurrences'])
                with col2:
                    st.metric("ì—°ì† ë°œìƒ í™•ë¥ ", f"{combined_stats['sequential_probability']:.1%}")
                with col3:
                    st.metric("í‰ê·  ì „í™˜ íšŸìˆ˜", f"{combined_stats['avg_transitions']:.1f}")
    
    # ì˜¤ë¥¸ìª½ ì»¬ëŸ¼: API ê¸°ë°˜ ë¶„ì„
    with right_col:
        st.markdown("## API ê¸°ë°˜ ê³ ê¸‰ ë¶„ì„")
        st.info("ğŸ¤– ë” ì •í™•í•œ ì˜ˆì¸¡ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©í•˜ì„¸ìš”. ì‘ë‹µ ì‹œê°„ì´ ë‹¤ì†Œ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # API ì„¤ì •
        with st.expander("API ì„¤ì •"):
            st.markdown("""
            ### Hugging Face API í† í° ì„¤ì • ê°€ì´ë“œ
            1. [Hugging Face Settings](https://huggingface.co/settings/tokens)ì— ì ‘ì†
            2. "New token" ë²„íŠ¼ í´ë¦­ í›„ Access Token ìƒì„±
            3. ìƒì„±ëœ í† í°ì„ ì•„ë˜ì— ì…ë ¥
            """)
            
            if "hf_api_token" in st.session_state:
                st.success("API í† í°ì´ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                if st.button("API í† í° ì¬ì„¤ì •", key="reset_token"):
                    del st.session_state.hf_api_token
                    st.experimental_rerun()
            else:
                api_token = st.text_input(
                    "Hugging Face API í† í°ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    type="password",
                    help="API í† í°ì€ huggingface.coì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                if api_token:
                    st.session_state.hf_api_token = api_token
                    st.success("API í† í°ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # API ê¸°ë°˜ íŒ¨í„´ ë¶„ì„
        pattern_api = st.text_input("íŒ¨í„´ ì…ë ¥ (ì˜ˆ: aa, ab, ba, bb)", key="pattern_input_api")
        if pattern_api and "hf_api_token" in st.session_state:
            with st.spinner("AI ëª¨ë¸ì´ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                prediction = get_huggingface_prediction(pattern_api)
                if prediction:
                    st.markdown(f"""
                        <div class="prediction-text">
                        ì˜ˆì¸¡ ë°©ë²•: {prediction['method']}<br>
                        ë‹¤ìŒ íŒ¨í„´ ì˜ˆì¸¡: {prediction['next_pattern']}<br>
                        ì‹ ë¢°ë„: {prediction['confidence']:.1%}<br>
                        </div>
                    """, unsafe_allow_html=True)
                    
                    with st.expander("ìƒì„¸ ë¶„ì„ ì •ë³´"):
                        st.write("íŒ¨í„´ íŠ¹ì„± ë¶„ì„:")
                        st.json({
                            "íŒ¨í„´ ê¸¸ì´": len(pattern_api),
                            "ë°˜ë³µì„±": len(set(pattern_api)) == 1,
                            "ì „í™˜ íšŸìˆ˜": sum(1 for i in range(len(pattern_api)-1) if pattern_api[i] != pattern_api[i+1])
                        })
                else:
                    st.error("API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        elif pattern_api:
            st.warning("API í† í°ì„ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    # í•˜ë‹¨ì— í†µê³„ ë°ì´í„° í‘œì‹œ
    st.markdown("---")
    st.subheader("ìµœê·¼ íŒ¨í„´ ì „ì´ ë°ì´í„°")
    if not df.empty:
        st.dataframe(df[['pattern1', 'result1', 'pattern2', 'result2', 'transition_type', 'transition_count']])

if __name__ == "__main__":
    main() 